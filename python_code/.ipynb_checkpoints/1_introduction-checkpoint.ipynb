{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# <center>Semester project - Guessing the fingerings</center>\n",
    "<center>Raphaël Latty<br /><br />Supervised by Marta Martinez-Camara and Robin Scheibler</center>\n",
    "<center><br />School of Computer and Communication Sciences - LCAV<br /><br />École Polytechnique Fédérale, Lausanne, Switzerland<br /><br />Spring 2017</center>\n",
    "\n",
    "<br /><br /><div style=\"text-align:justify;text-indent:15px;\"> ABSTRACT - On most musical instruments, specially in the guitar, it is possible to play the same note or chord in multiple ways. In this project, we develop a simple, audio-based method to estimate the fingering of a note played on an acoustic guitar from an audio recording. Estimating the position used to play a particular note or chord has several applications, including musical training and musical education. This topic stands at the intersection of two disciplines: Musical Acoustics and Signal Processing. On one hand, acoustics has been studied extensively and there exists a plethora of theories on all the common instruments. On the other hand, signal processing tools allows one to analyze and process musical sounds, and to study the behavior of musical instruments in practice. The acoustic guitar is a common, widespread instrument, and the problem of estimating the fingering, i.e. the position along the fretboard, used to play a note or a chord is therefore relevant. </div>\n",
    "\n",
    "\n",
    "## I. INTRODUCTION <br />\n",
    "\n",
    "<div style=\"text-align:justify;text-indent:15px;\"> It is well known by musicians that the same note or chord can be played using different fingerings. On the guitar for example, the guitarist can press the strings at different spots along the fingerboard to produce the exact same note. It may be done for several reasons: to facilitate the playing of a melody, or to produce a particular color in the sound. The goal of this project is to build a system that automatically estimates, from an audio recording, the fingering that was used to play a given note or chord on an acoustic guitar. This kind of technique is sometimes called Automatic Music Transcription, and is part of a broader field called Music Information Retrieval (MIR). Potential applications of such a system could include musical training or musical education, or it could be used for the analysis of famous historical records for example. </div><br />\n",
    "\n",
    "<div style=\"text-align:justify;\"> Several methods to automatically estimate the fingering of a note or a chord on a guitar have been developed. Some of them use multiple supports (video, audio, sensors, or a combination of these), while other audio-based techniques rely on statistical models and machine learning tools ([5], [6]). In this project walk-through, we present a simpler audio-based system that aims to estimate the fingering of a note from an audio recording of an acoustic guitar note. Our system focuses on just one feature: the inharmonicity constant of the sounds. Building on theoretical results, we will explore several techniques that may be used to estimate the inharmonicity, and assemble everything into a complete system that classifies the recordings according with the fingerings that were used to generate them. </div><br />\n",
    "\n",
    "<div style=\"text-align:justify;\"> The rest of the report is organized in chapters as follows. In Chapter II, we will list and illustrate a number of theoretical results on vibrating strings and the guitar in general. The goal is to understand how guitar tones are generated, and to get an idea of what can be used to distinguish different fingerings. In Chapter III, we will implement and present a simple model for a vibrating guitar string, in order to verify a number of assumptions. In our context, spectrum estimation techniques are useful to track the partials accurately. Therefore, Chapter IV is devoted to spectral estimation, in particular to the well-known MUSIC algorithm. We then explore in detail the effect of inharmonicity in Chapter V, both on a theoretical level and for real recordings. In Chapter VI, we assemble all the tools developed so far and build a simple inharmonicity-based classifier. We also present and discuss the final results obtained with our system. Finally, Chapter VII concludes our work and includes a list of all the references used throughout this project. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
